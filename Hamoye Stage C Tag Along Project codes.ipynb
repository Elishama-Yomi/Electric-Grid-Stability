{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there is a direct relationship between the stab and stabf column, \n",
    "#I am dropping the stab column so I can use stabf instead.\n",
    "df.drop('stab', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.930406</td>\n",
       "      <td>9.487627</td>\n",
       "      <td>2.376523</td>\n",
       "      <td>6.187797</td>\n",
       "      <td>3.343416</td>\n",
       "      <td>-0.658054</td>\n",
       "      <td>-1.449106</td>\n",
       "      <td>-1.236256</td>\n",
       "      <td>0.601709</td>\n",
       "      <td>0.779642</td>\n",
       "      <td>0.813512</td>\n",
       "      <td>0.608385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3.392299</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>2.954947</td>\n",
       "      <td>6.894759</td>\n",
       "      <td>4.349512</td>\n",
       "      <td>-1.663661</td>\n",
       "      <td>-0.952437</td>\n",
       "      <td>-1.733414</td>\n",
       "      <td>0.502079</td>\n",
       "      <td>0.567242</td>\n",
       "      <td>0.285880</td>\n",
       "      <td>0.366120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.364034</td>\n",
       "      <td>2.842030</td>\n",
       "      <td>8.776391</td>\n",
       "      <td>1.008906</td>\n",
       "      <td>4.299976</td>\n",
       "      <td>-1.380719</td>\n",
       "      <td>-0.943884</td>\n",
       "      <td>-1.975373</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.986505</td>\n",
       "      <td>0.149286</td>\n",
       "      <td>0.145984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9.631511</td>\n",
       "      <td>3.994398</td>\n",
       "      <td>2.757071</td>\n",
       "      <td>7.821347</td>\n",
       "      <td>2.514755</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>-0.649915</td>\n",
       "      <td>-0.898510</td>\n",
       "      <td>0.365246</td>\n",
       "      <td>0.587558</td>\n",
       "      <td>0.889118</td>\n",
       "      <td>0.818391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6.530527</td>\n",
       "      <td>6.781790</td>\n",
       "      <td>4.349695</td>\n",
       "      <td>8.673138</td>\n",
       "      <td>3.492807</td>\n",
       "      <td>-1.390285</td>\n",
       "      <td>-1.532193</td>\n",
       "      <td>-0.570329</td>\n",
       "      <td>0.073056</td>\n",
       "      <td>0.505441</td>\n",
       "      <td>0.378761</td>\n",
       "      <td>0.942631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0     2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1     9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2     8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3     0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4     3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  2.930406  9.487627  2.376523  6.187797  3.343416 -0.658054 -1.449106   \n",
       "9996  3.392299  1.274827  2.954947  6.894759  4.349512 -1.663661 -0.952437   \n",
       "9997  2.364034  2.842030  8.776391  1.008906  4.299976 -1.380719 -0.943884   \n",
       "9998  9.631511  3.994398  2.757071  7.821347  2.514755 -0.966330 -0.649915   \n",
       "9999  6.530527  6.781790  4.349695  8.673138  3.492807 -1.390285 -1.532193   \n",
       "\n",
       "            p4        g1        g2        g3        g4  \n",
       "0    -1.723086  0.650456  0.859578  0.887445  0.958034  \n",
       "1    -1.255012  0.413441  0.862414  0.562139  0.781760  \n",
       "2    -0.920492  0.163041  0.766689  0.839444  0.109853  \n",
       "3    -0.997374  0.446209  0.976744  0.929381  0.362718  \n",
       "4    -0.554305  0.797110  0.455450  0.656947  0.820923  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "9995 -1.236256  0.601709  0.779642  0.813512  0.608385  \n",
       "9996 -1.733414  0.502079  0.567242  0.285880  0.366120  \n",
       "9997 -1.975373  0.487838  0.986505  0.149286  0.145984  \n",
       "9998 -0.898510  0.365246  0.587558  0.889118  0.818391  \n",
       "9999 -0.570329  0.073056  0.505441  0.378761  0.942631  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining the dependent variable and independent variables\n",
    "X = df.iloc[:, :-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       unstable\n",
       "1         stable\n",
       "2       unstable\n",
       "3       unstable\n",
       "4       unstable\n",
       "          ...   \n",
       "9995    unstable\n",
       "9996      stable\n",
       "9997      stable\n",
       "9998    unstable\n",
       "9999    unstable\n",
       "Name: stabf, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:, -1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the standard scaler to transform the train and the test sets.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "normalized_train_df = scaler.fit_transform(x_train)\n",
    "normalized_train_df = pd.DataFrame(normalized_train_df, columns = x_train.columns)\n",
    "\n",
    "normalized_test_df = scaler.transform(x_test)\n",
    "normalized_test_df = pd.DataFrame(normalized_test_df, columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9191    0.8778    0.8980       712\n",
      "    unstable     0.9341    0.9573    0.9456      1288\n",
      "\n",
      "    accuracy                         0.9290      2000\n",
      "   macro avg     0.9266    0.9176    0.9218      2000\n",
      "weighted avg     0.9288    0.9290    0.9286      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "RandomForest = RandomForestClassifier(random_state=1)\n",
    "RandomForest.fit(normalized_train_df, y_train)\n",
    "RandomForest_predicted = RandomForest.predict(normalized_test_df)\n",
    "print(classification_report(y_test, RandomForest_predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9410    0.8511    0.8938       712\n",
      "    unstable     0.9218    0.9705    0.9455      1288\n",
      "\n",
      "    accuracy                         0.9280      2000\n",
      "   macro avg     0.9314    0.9108    0.9197      2000\n",
      "weighted avg     0.9287    0.9280    0.9271      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extra trees classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ExtraTree = ExtraTreesClassifier(random_state=1)\n",
    "ExtraTree.fit(normalized_train_df, y_train)\n",
    "ExtraTree_predicted = ExtraTree.predict(normalized_test_df)\n",
    "print(classification_report(y_test, ExtraTree_pred, zero_division=True, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\programdata\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n",
      "[13:36:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#Using xgboost to train an extreme boosting model \n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "Extreme = XGBClassifier(random_state=1)\n",
    "Extreme.fit(normalized_train_df, y_train)\n",
    "Extreme_predicted = Extreme.predict(normalized_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9351    0.9101    0.9224       712\n",
      "    unstable     0.9510    0.9651    0.9580      1288\n",
      "\n",
      "    accuracy                         0.9455      2000\n",
      "   macro avg     0.9430    0.9376    0.9402      2000\n",
      "weighted avg     0.9453    0.9455    0.9453      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, Extreme_predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.2-py3-none-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: wheel in c:\\programdata\\anaconda3\\lib\\site-packages (from lightgbm) (0.35.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9276    0.9003    0.9138       712\n",
      "    unstable     0.9458    0.9612    0.9534      1288\n",
      "\n",
      "    accuracy                         0.9395      2000\n",
      "   macro avg     0.9367    0.9307    0.9336      2000\n",
      "weighted avg     0.9393    0.9395    0.9393      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using lightgbm to train a light gradient boosting model\n",
    "!pip install lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "LightGradient = LGBMClassifier(random_state=1)\n",
    "LightGradient.fit(normalized_train_df, y_train)\n",
    "LightGradient_predicted = LightGradient.predict(normalized_test_df)\n",
    "print(classification_report(y_test, LightGradient_predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'max_features': max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.7min finished\n"
     ]
    }
   ],
   "source": [
    "#Randomised Search Cross Validation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "tree2 = ExtraTreesClassifier(random_state=1)\n",
    "clf = RandomizedSearchCV(tree2, hyperparameter_grid, cv=5, n_iter=10, scoring = 'accuracy', n_jobs = -1, verbose = 1, random_state=1)\n",
    "search_result = clf.fit(normalized_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for the best parameter for the model\n",
    "search_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with this parameter to test the model's performance\n",
    "tuned_tree = ExtraTreesClassifier(n_estimators=1000, min_samples_split=2, \n",
    "                                 min_samples_leaf=8, max_features=None, random_state=1)\n",
    "tuned_tree.fit(normalized_train_df, y_train)\n",
    "tuned_tree_pred = tuned_tree.predict(normalized_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      stable     0.9211    0.8694    0.8945       712\n",
      "    unstable     0.9300    0.9589    0.9442      1288\n",
      "\n",
      "    accuracy                         0.9270      2000\n",
      "   macro avg     0.9256    0.9141    0.9193      2000\n",
      "weighted avg     0.9268    0.9270    0.9265      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report for this hyperparameter tuning\n",
    "print(classification_report(y_test, tuned_tree_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature importance\n",
    "feat_importance = pd.Series(tuned_tree.feature_importances_, index=X.columns)\n",
    "feat_importance.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
